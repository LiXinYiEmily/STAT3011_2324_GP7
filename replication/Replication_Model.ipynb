{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4LpcOVaYpje"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is the Model part of the replication. We should note that because the original notebook didn't set the random seed, the ROC_AUC scores here are not exactly the same with the original one, but all models here can run successfully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd3jk_NcZpD-"
      },
      "source": [
        "Import sklearn packages needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1WJ7LobbYgjH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO5jMrBiZvxh"
      },
      "source": [
        "Split the training set and test set with ratio 3:1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuV06dXVY_u8"
      },
      "outputs": [],
      "source": [
        "X = training_data.iloc[:, 1:]\n",
        "y = training_data['seriousdlqin2yrs']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8noy0lT3Z5Fb"
      },
      "source": [
        "### KNN Classifier\n",
        "\n",
        "The 1st baseline model is the KNN classifier. The following are the parameters we choose.\n",
        "\n",
        "- n_neighbors=5: It means that the classifier will consider the 5 nearest neighbors to a given data point when making a prediction.\n",
        "\n",
        "- weights='uniform': It means all neighbors have equal weight.\n",
        "\n",
        "- algorithm='auto': The model will automatically select the most appropriate algorithm among 'ball_tree', 'kd_tree', and 'brute' based on the input data.\n",
        "\n",
        "- leaf_size: This parameter is relevant when using the 'ball_tree' or 'kd_tree' algorithm. It determines the leaf size of the tree data structure used for efficient nearest neighbor searches.\n",
        "\n",
        "- metric='minkowski': This parameter specifies the distance metric used to compute the distances between points.\n",
        "\n",
        "- p=2: This parameter determines the power parameter for the **Minkowski distance** metric. Here p=2 which corresponds to the **Euclidean distance** metric, which is commonly used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "yUPQTCh7ZLzg",
        "outputId": "480f3a2a-0760-47b2-c742-cc22d063f374"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30,\n",
        "                           metric='minkowski', metric_params=None, p=2)\n",
        "knn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWH8TeH5bvPS"
      },
      "source": [
        "It calculates the accuracy of the KNN classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8-fXcpgbgoD",
        "outputId": "1ba07165-c547-4eb8-b821-7424dfe98d97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9310133333333334"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiaFqVYJcUmE"
      },
      "source": [
        "It calculates the ROC_AUC score of the KNN classifier. The following are the parameters we choose.\n",
        "\n",
        "- average='macro': This parameter determines how the ROC AUC scores are aggregated in the case of multiclass classification. It calculates the average ROC AUC score for each class independently and then takes the mean. In our case the y is binary, therefore we don't need to set this parameter.\n",
        "\n",
        "- sample_weight=None: All samples have the wame weight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpKdsXCKbjQW",
        "outputId": "5bc3fdb1-7258-42af-9ff8-3895874ab263"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5902430034525364"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = knn.predict_proba(np.array(X_test.values))[:,1]\n",
        "roc_auc_score(y_test, y_pred , average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05AK6sD4c8lj"
      },
      "source": [
        "### Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDnJkEDTdoIO"
      },
      "source": [
        "The 2nd baseline model is the Logistic Regression classifier. The following are the parameters we choose.\n",
        "\n",
        "- penalty='l1': We choose the L1 type of regularization penalty here.\n",
        "\n",
        "- dual=False: This parameter is relevant when the number of samples is larger than the number of features. It determines whether to solve the dual or primal optimization problem. False indicates that the primal problem is solved.\n",
        "\n",
        "\n",
        "- fit_intercept: This parameter determines whether to include an intercept term in the logistic regression model.\n",
        "\n",
        "- intercept_scaling=1: It scales the intercept term.\n",
        "\n",
        "- multi_class='ovr': This parameter determines the strategy for handling multi-class classification problems. 'ovr' stands for one-vs-rest.\n",
        "\n",
        "- class_weight=None: This parameter allows you to assign different weights to different classes. It can be useful when dealing with imbalanced class distributions. None means all classes have equal weight.\n",
        "\n",
        "- solver='liblinear': This parameter determines the algorithm used for optimization. The 'liblinear' is suitable for small datasets.\n",
        "\n",
        "- max_iter=1000: This parameter specifies the maximum number of iterations for the optimization algorithm to converge.\n",
        "\n",
        "- tol=0.0001: This parameter specifies the tolerance for convergence of the optimization algorithm. The algorithm stops if the change in the objective function value is less than tol.\n",
        "\n",
        "- C=1: $\\frac{1}{C}$ controls the inverse of the regularization strength. It determines the trade-off between fitting the training data and keeping the model coefficients small to avoid overfitting.\n",
        "\n",
        "- random_state=None: This parameter sets the random seed for reproducible results.\n",
        "\n",
        "- verbose=2: This parameter controls the verbosity of the training process. Setting it to 2 enables the output of progress messages during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "rRB1dMS8c8JN",
        "outputId": "97f5043d-948a-45ad-e114-cb6069067ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LibLinear]"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;,\n",
              "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;,\n",
              "                   verbose=2)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(multi_class='ovr', penalty='l1', solver='liblinear',\n",
              "                   verbose=2)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr = LogisticRegression(penalty='l1', dual=False, fit_intercept=True, intercept_scaling=1,\n",
        "                        multi_class='ovr', class_weight=None,\n",
        "                        solver='liblinear', tol=0.0001, C=1.0, max_iter=100,\n",
        "                        random_state=None, verbose=2)\n",
        "lr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r8ssBs9m4Yw"
      },
      "source": [
        "It calculates the accuracy of the Logistic Regression classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M2nON-WdG5P",
        "outputId": "e7413f56-ecc7-4d8b-b3e2-5fa2f02dc6bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9354666666666667"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1yqLRSYdbDs"
      },
      "source": [
        "It calculates the ROC_AUC score of the Logistic Regression classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M45Vm0ICdJS6",
        "outputId": "efc3554a-ed62-4a31-8e71-96b4e757fa6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8494489584447374"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = lr.predict_proba(np.array(X_test.values))[:,1]\n",
        "roc_auc_score(y_test, y_pred , average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lkxXcAsmWu9"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjvWgUnenlqR"
      },
      "source": [
        "The 3rd baseline model is the Random Forest classifier. The following are the parameters we choose.\n",
        "\n",
        "- n_estimators=10: This parameter specifies the number of decision trees to be created in the random forest.\n",
        "\n",
        "- criterion='gini': Here we use the Gini impurity as the criterion when split in each decision tree.\n",
        "\n",
        "- max_depth=None: This parameter specifies the maximum depth of each decision tree in the random forest. The default value is None, which means that the decision trees will be grown until all leaves are pure or until all leaves contain fewer samples than min_samples_split.\n",
        "\n",
        "- min_samples_split=2: This parameter sets the minimum number of samples required to split an internal node in the decision trees. The value value here is 2, which means that a node must have at least two samples to be considered for splitting.\n",
        "\n",
        "- min_samples_leaf=1: This parameter sets the minimum number of samples required to be at a leaf node in the decision trees.\n",
        "\n",
        "- min_weight_fraction_leaf=0: This parameter sets the minimum weighted fraction of the total number of samples required to be at a leaf node. 0 means that the weight of the samples is not considered.\n",
        "\n",
        "- max_features='auto': This parameter determines the number of features to consider when looking for the best split at each node. 'auto' uses the square root of the total number of features.\n",
        "\n",
        "- max_leaf_nodes=None: This parameter limits the maximum number of leaf nodes in each decision tree. The default value is None, which means there is no maximum limit.\n",
        "\n",
        "- bootstrap=True: This parameter determines whether bootstrap samples are used when building decision trees.\n",
        "\n",
        "- oob_score=False: This parameter determines whether to use out-of-bag samples to estimate the generalization accuracy of the random forest.\n",
        "\n",
        "- n_jobs=1: This parameter specifies the number of parallel jobs to run during training and prediction.\n",
        "\n",
        "- random_state=None: This parameter sets the random seed for reproducible results.\n",
        "\n",
        "- verbose=2: This parameter controls the verbosity of the training process. Setting it to 2 enables the output of progress messages during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "x1WVzqKcdRvL",
        "outputId": "ea50c368-09cc-4428-b695-2cda473dc58e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=&#x27;auto&#x27;, n_estimators=10, n_jobs=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=&#x27;auto&#x27;, n_estimators=10, n_jobs=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_features='auto', n_estimators=10, n_jobs=1)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2,\n",
        "                               min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
        "                               max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1,\n",
        "                               random_state=None, verbose=0)\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBqwAHuxm8qj"
      },
      "source": [
        "It calculates the accuracy of the Random Forest classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujG0lr-Wmk_R",
        "outputId": "17dadd85-c467-4e1c-ce0a-1c8e56c2430d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.93128"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdcgvEoHnKAo"
      },
      "source": [
        "It calculates the ROC_AUC score of the Random Forest classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7jy6tWqmqCd",
        "outputId": "4315959c-ab47-4964-8c8f-61fb62926318"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7723554070633775"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = rf.predict_proba(np.array(X_test.values))[:,1]\n",
        "roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E5yyiQ1pvsr"
      },
      "source": [
        "### AdaBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ZFmGzqlumzKI",
        "outputId": "1f33439a-c2aa-4414-d8f7-6e80418c64fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=200)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "AdaBoostClassifier(n_estimators=200)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "ada = AdaBoostClassifier(n_estimators=200, learning_rate=1.0)\n",
        "ada.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYhdZvQiudZs"
      },
      "source": [
        "It calculates the accuracy of the AdaBoosting classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV7_TdpYp042",
        "outputId": "c1fccf5b-a8d5-4863-9003-0ec605ba0e53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.93416"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ada.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Depa6Zuhef"
      },
      "source": [
        "It calculates the ROC_AUC score of the AdaBoosting classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icRVsz_MqsfU",
        "outputId": "3344b3db-0048-4154-802b-dda20e571844"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8607267479275506"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = ada.predict_proba(np.array(X_test.values))[:,1]\n",
        "roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVLynwOyrEFK"
      },
      "source": [
        "### Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14ILH1DArgmT"
      },
      "source": [
        "The 5th baseline model is the Gradient Boosting classifier. The following are the parameters we choose.\n",
        "\n",
        "- loss='deviance': This parameter specifies the loss function to be optimized during the gradient boosting process. The 'deviance' corresponds to the logistic regression loss for binary classification problems.\n",
        "\n",
        "- learning_rate=0.1: This parameter controls the shrinkage of the contribution of each tree in the ensemble.\n",
        "\n",
        "- n_estimators=200: This parameter specifies the number of trees to be built.\n",
        "\n",
        "- subsample=1: This parameter controls the fraction of samples to be used for fitting each tree. Values less than 1.0 introduce stochasticity into the gradient boosting process, which can help reduce overfitting.\n",
        "\n",
        "- min_samples_split=2: This parameter sets the minimum number of samples required to split an internal node in each decision tree.\n",
        "\n",
        "- min_samples_leaf=1: This parameter sets the minimum number of samples required to be at a leaf node in each decision tree.\n",
        "\n",
        "- min_weight_fraction_leaf=0: This parameter sets the minimum weighted fraction of the total number of samples required to be at a leaf node. 0 means that the weight of the samples is not considered.\n",
        "\n",
        "- max_depth=3: This parameter specifies the maximum depth of each decision tree.\n",
        "\n",
        "- init=None: This parameter specifies the initial estimator for the gradient boosting ensemble. None means a simple decision tree with a depth of 1 is used.\n",
        "\n",
        "- random_state=None: This parameter sets the random seed for reproducible results.\n",
        "\n",
        "- max_features=None: This parameter determines the number of features to consider when looking for the best split at each node. None means all features are considered.\n",
        "\n",
        "- verbose=2: This parameter controls the verbosity of the training process. Setting it to 2 enables the output of progress messages during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "X-BllIw2rBcP",
        "outputId": "67abdaf5-20bd-4beb-f3b4-1bc63047983b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(loss=&#x27;deviance&#x27;, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(loss=&#x27;deviance&#x27;, n_estimators=200)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GradientBoostingClassifier(loss='deviance', n_estimators=200)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gb = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=1.0,\n",
        "                                min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3,\n",
        "                                init=None, random_state=None, max_features=None, verbose=0)\n",
        "gb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL3risrauYKb"
      },
      "source": [
        "It calculates the accuracy of the Gradient Boosting classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtX9su9Kt85W",
        "outputId": "6f40f429-6759-4fc6-c138-f70a66aac26c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9351466666666667"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gb.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWrm2P1kuk9F"
      },
      "source": [
        "It calculates the ROC_AUC score of the Gradient Boosting classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlPCvE64uJGe",
        "outputId": "6cbd201e-906c-4c74-8a61-de20c7cd3f0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8658695722050163"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = gb.predict_proba(np.array(X_test.values))[:,1]\n",
        "roc_auc_score(y_test, y_pred, average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq9ZZC97uuYd"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c8aGmyppuSo6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Generate the cross validation score for each models\n",
        "def cvDictGen(functions, metric, X_train=X, y_train=y, cv=5, verbose=1):\n",
        "    \"\"\"\n",
        "    func: list of functions to be evaluated.\n",
        "\n",
        "    metric: Metric of the performance.\n",
        "\n",
        "    X_train: X of the training set.\n",
        "\n",
        "    y_train: y of the training set.\n",
        "\n",
        "    verbose: Whether to print out the process.\n",
        "    \"\"\"\n",
        "\n",
        "    cvDict = {}\n",
        "    for func in functions:\n",
        "        cvScore = cross_val_score(func, X_train, y_train, cv=cv, verbose=verbose, scoring=metric)\n",
        "        cvDict[str(func).split('(')[0]] = [cvScore.mean(), cvScore.std()]\n",
        "\n",
        "    return cvDict\n",
        "\n",
        "# Normalize the cross validation score for each models\n",
        "def cvDictNormalize(cvDict):\n",
        "\n",
        "    cvDictNormalized = {}\n",
        "    norm1 = sum([lst[0] for lst in cvDict.values()])\n",
        "    norm2 = sum([lst[1] for lst in cvDict.values()])\n",
        "    for key in cvDict.keys():\n",
        "            cvDictNormalized[key] = ['{:0.2f}'.format((cvDict[key][0]/norm1)),\n",
        "                                     '{:0.2f}'.format((cvDict[key][1]/norm2))]\n",
        "    return cvDictNormalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bv9AjDXzzyR"
      },
      "source": [
        "The unNormalized Cross Validation Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9aqju-xv7qE",
        "outputId": "6e965cdb-cb21-425e-eb34-7fda03e8cadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'KNeighborsClassifier': [0.595871676666674, 0.0024190748279330353],\n",
              " 'LogisticRegression': [0.849200473963769, 0.0036337968565900935],\n",
              " 'RandomForestClassifier': [0.7777348588207509, 0.005894740403345748],\n",
              " 'AdaBoostClassifier': [0.8586812528322133, 0.0021126810786966793],\n",
              " 'GradientBoostingClassifier': [0.8639067246517946, 0.0026203413657827955]}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cvDict = cvDictGen(functions=[knn, lr, rf, ada, gb], metric='roc_auc')\n",
        "cvDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDTY2xg6zt7w"
      },
      "source": [
        "The Normalized Cross Validation Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw1Q0w-7yBYn",
        "outputId": "1b7b54a0-3b6e-4a62-860c-14fadbe0d375"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'KNeighborsClassifier': ['0.15', '0.15'],\n",
              " 'LogisticRegression': ['0.22', '0.22'],\n",
              " 'RandomForestClassifier': ['0.20', '0.35'],\n",
              " 'AdaBoostClassifier': ['0.22', '0.13'],\n",
              " 'GradientBoostingClassifier': ['0.22', '0.16']}"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cvDictNormalize(cvDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "5O5JBvmf0PH5"
      },
      "outputs": [],
      "source": [
        "from joblib import dump\n",
        "\n",
        "models = [knn, lr, rf, ada, gb]\n",
        "# Store the fitted model\n",
        "for mol in models:\n",
        "  dump(mol, f'/content/drive/MyDrive/STAT3011/{mol}.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "L0le56fgKubK"
      },
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "\n",
        "# Load the stored model\n",
        "ada = load('/content/drive/MyDrive/STAT3011/AdaBoostClassifier(n_estimators=200).joblib')\n",
        "gb = load(\"/content/drive/MyDrive/STAT3011/GradientBoostingClassifier(loss='deviance', n_estimators=200).joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlrlBGlsxVVt"
      },
      "source": [
        "### Hyper parameter optimization using Randomized search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "FrTQnqYbwFwy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v29Fr8HMMt1d"
      },
      "source": [
        "This step is the randomized cross validation (CV) search for the AdaBoosting. Combinations of Parameters will be randomly choosed and evaluated with the CV technique. Finally the parameter combination with the best CV performance will be chosen.\n",
        "\n",
        "The following are parameters for the RandomizedSearchCV.\n",
        "\n",
        "- estimator='ada': It specifies the model that will be tuned using randomized search.\n",
        "\n",
        "- param_distributions: This parameter is a dictionary containing the parameter distributions to sample from during the randomized search. Each key in the dictionary represents a hyperparameter of the estimator, and the corresponding value is a distribution or list of possible values for that hyperparameter.\n",
        "\n",
        "- n_iter=5: This parameter specifies the number of parameter settings that will be sampled from the param_distributions.\n",
        "\n",
        "- scoring='roc_auc': This parameter specifies the scoring metric that will be used to evaluate the performance of each parameter setting.\n",
        "\n",
        "- cv=None: This parameter determines the cross-validation strategy used to evaluate the performance of each parameter setting. None means the default 5-fold cross-validation will be used.\n",
        "\n",
        "- verbose=2: This parameter controls the verbosity of the training process. Setting it to 2 enables the output of progress messages during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-wAX2W-xZka",
        "outputId": "f493e334-7256-4807-b07c-730239157d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "[CV] END ....................................n_estimators=10; total time=   3.8s\n",
            "[CV] END ....................................n_estimators=10; total time=   2.0s\n",
            "[CV] END ....................................n_estimators=10; total time=   1.4s\n",
            "[CV] END ....................................n_estimators=10; total time=   1.8s\n",
            "[CV] END ....................................n_estimators=10; total time=   0.9s\n",
            "[CV] END ....................................n_estimators=50; total time=   4.1s\n",
            "[CV] END ....................................n_estimators=50; total time=   6.3s\n",
            "[CV] END ....................................n_estimators=50; total time=   5.5s\n",
            "[CV] END ....................................n_estimators=50; total time=   6.9s\n",
            "[CV] END ....................................n_estimators=50; total time=   5.6s\n",
            "[CV] END ...................................n_estimators=100; total time=  12.6s\n",
            "[CV] END ...................................n_estimators=100; total time=  13.2s\n",
            "[CV] END ...................................n_estimators=100; total time=  12.3s\n",
            "[CV] END ...................................n_estimators=100; total time=  11.5s\n",
            "[CV] END ...................................n_estimators=100; total time=  12.2s\n",
            "[CV] END ...................................n_estimators=200; total time=  26.1s\n",
            "[CV] END ...................................n_estimators=200; total time=  26.9s\n",
            "[CV] END ...................................n_estimators=200; total time=  27.8s\n",
            "[CV] END ...................................n_estimators=200; total time=  25.0s\n",
            "[CV] END ...................................n_estimators=200; total time=  20.4s\n",
            "[CV] END ...................................n_estimators=420; total time=  50.2s\n",
            "[CV] END ...................................n_estimators=420; total time=  50.3s\n",
            "[CV] END ...................................n_estimators=420; total time=  46.8s\n",
            "[CV] END ...................................n_estimators=420; total time=  50.2s\n",
            "[CV] END ...................................n_estimators=420; total time=  39.4s\n"
          ]
        }
      ],
      "source": [
        "adaHyperParams = {'n_estimators': [10,50,100,200,420]}\n",
        "\n",
        "gridSearchAda = RandomizedSearchCV(estimator=ada, param_distributions=adaHyperParams,\n",
        "                                   n_iter=5, scoring='roc_auc', cv=None, verbose=2).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmQ7FVWQxiP6",
        "outputId": "4abeb7ce-386e-4375-873f-5e089cd24d03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'n_estimators': 100}, 0.8562169556184855)"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gridSearchAda.best_params_, gridSearchAda.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtetcXFXxrEN"
      },
      "source": [
        "#### GradientBoosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WuAjpBROLAv"
      },
      "source": [
        "This step is the randomized cross validation (CV) search for the GradientBoosting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbxERdqGxow5",
        "outputId": "197d2354-69d9-44d5-cad0-2286ac9dcf6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ........loss=deviance, max_depth=3, n_estimators=75; total time=  13.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ........loss=deviance, max_depth=3, n_estimators=75; total time=  10.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ........loss=deviance, max_depth=3, n_estimators=75; total time=  16.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......loss=deviance, max_depth=8, n_estimators=341; total time= 2.1min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......loss=deviance, max_depth=8, n_estimators=341; total time= 2.1min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......loss=deviance, max_depth=8, n_estimators=341; total time= 2.1min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......loss=deviance, max_depth=4, n_estimators=480; total time= 1.5min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......loss=deviance, max_depth=4, n_estimators=480; total time= 1.5min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......loss=deviance, max_depth=4, n_estimators=480; total time= 1.5min\n",
            "[CV] END ....loss=exponential, max_depth=7, n_estimators=347; total time= 1.9min\n",
            "[CV] END ....loss=exponential, max_depth=7, n_estimators=347; total time= 1.9min\n",
            "[CV] END ....loss=exponential, max_depth=7, n_estimators=347; total time= 1.9min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ........loss=deviance, max_depth=9, n_estimators=39; total time=  16.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ........loss=deviance, max_depth=9, n_estimators=39; total time=  17.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ........loss=deviance, max_depth=9, n_estimators=39; total time=  16.1s\n",
            "[CV] END ....loss=exponential, max_depth=6, n_estimators=110; total time=  31.6s\n",
            "[CV] END ....loss=exponential, max_depth=6, n_estimators=110; total time=  30.0s\n",
            "[CV] END ....loss=exponential, max_depth=6, n_estimators=110; total time=  30.8s\n",
            "[CV] END ....loss=exponential, max_depth=9, n_estimators=129; total time=  54.1s\n",
            "[CV] END ....loss=exponential, max_depth=9, n_estimators=129; total time=  53.7s\n",
            "[CV] END ....loss=exponential, max_depth=9, n_estimators=129; total time=  55.4s\n",
            "[CV] END ....loss=exponential, max_depth=5, n_estimators=161; total time=  37.1s\n",
            "[CV] END ....loss=exponential, max_depth=5, n_estimators=161; total time=  38.2s\n",
            "[CV] END ....loss=exponential, max_depth=5, n_estimators=161; total time=  37.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......loss=deviance, max_depth=7, n_estimators=496; total time= 2.7min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......loss=deviance, max_depth=7, n_estimators=496; total time= 2.7min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .......loss=deviance, max_depth=7, n_estimators=496; total time= 2.7min\n",
            "[CV] END ....loss=exponential, max_depth=1, n_estimators=181; total time=   9.5s\n",
            "[CV] END ....loss=exponential, max_depth=1, n_estimators=181; total time=   9.9s\n",
            "[CV] END ....loss=exponential, max_depth=1, n_estimators=181; total time=  10.2s\n"
          ]
        }
      ],
      "source": [
        "gbHyperParams = {'loss' : ['deviance', 'exponential'],\n",
        "                 'n_estimators': randint(10, 500),\n",
        "                 'max_depth': randint(1,10)}\n",
        "\n",
        "gridSearchGB = RandomizedSearchCV(estimator=gb, param_distributions=gbHyperParams,\n",
        "                                  n_iter=10, scoring='roc_auc', cv=3, verbose=2).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg3e-7qjxyVz",
        "outputId": "c77588e6-d20c-41f5-b3fc-56337aa0a86f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'loss': 'exponential', 'max_depth': 5, 'n_estimators': 161},\n",
              " 0.860167795214304)"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gridSearchGB.best_params_, gridSearchGB.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jPKOlGgOYvH"
      },
      "source": [
        "### Train models with help of new hyper parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C2FZ1Emb2QZ"
      },
      "source": [
        "In this step we fit the model with the best parameters and check the cross validation performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aygcozmmYX4",
        "outputId": "cd907bf3-2be4-4c04-d0d3-8b8ad0192da0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "bestGb = gridSearchGB_best_estimator_.fit(X_train, y_train)\n",
        "bestAda = gridSearchAda_best_estimator_.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRUuKh35LqyR",
        "outputId": "f7a94bd5-605b-4534-855e-4ed4ce12f5d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'GradientBoostingClassifier': [0.863453647332082, 0.0026127847416857145],\n",
              " 'AdaBoostClassifier': [0.8591468159728505, 0.002580346154686282]}"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bestGb = gridSearchGB.best_estimator_.fit(X_train, y_train)\n",
        "bestAda = gridSearchAda.best_estimator_.fit(X_train, y_train)\n",
        "\n",
        "best_cvDict = cvDictGen(functions=[bestGb, bestAda], metric='roc_auc')\n",
        "best_cvDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfFAvw5QcNGu"
      },
      "source": [
        "The ROC_AUC score of the AdaBoosting with the grid search parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3XJxREePLct",
        "outputId": "91015ba4-087a-4c55-ba62-00ea320abb61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8610617616093497"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_ada = bestAda.predict_proba(np.array(X_test.values))[:,1]\n",
        "roc_auc_score(y_test, y_pred_ada, average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv3eNMrLcXU1"
      },
      "source": [
        "The ROC_AUC score of the GridentBoosting with the grid search parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvxJ8wqeOwQu",
        "outputId": "6f6d30f9-f23e-4d94-f916-2a52ef5f003b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.866200223773587"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_gb = bestGb.predict_proba(np.array(X_test.values))[:,1]\n",
        "roc_auc_score(y_test, y_pred_gb, average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLwTeN0ngLmy"
      },
      "source": [
        "### Feature Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b7D87NFgac1"
      },
      "source": [
        "In this step, we transform all features $x$ in X_train into $log(x+1)$, which can help to normalize its distribution and reduce the impact of extreme values or skewness. It is particularly useful when dealing with features that have a large scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "41iH9F7Vfrmx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "transformer = FunctionTransformer(np.log1p)\n",
        "X_train_transform = transformer.transform(np.array(X_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh_JRn50h5J5"
      },
      "source": [
        "Then we fit models with transformed X features using grid search parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJm4GJVRg-iE",
        "outputId": "c11437fa-cd16-4342-bf2a-c159950dc802"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "bestGbFitted_transformed = gridSearchGB.best_estimator_.fit(X_train_transform, y_train)\n",
        "bestAdaFitted_transformed = gridSearchAda.best_estimator_.fit(X_train_transform, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Joc0YFjLjJjx"
      },
      "source": [
        "Then we check the cross validation result and find that ROC_AUC scores of these two models are improved after the feature transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6iRXJCMhy5g",
        "outputId": "7ad8b364-c7b9-4c38-84c2-02215666ac8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'GradientBoostingClassifier': [0.8633363804012559, 0.0023194922989105814],\n",
              " 'AdaBoostClassifier': [0.8590733597107562, 0.001772821157510175]}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cvDictbestpara_transform = cvDictGen(functions=[bestGbFitted_transformed, bestAdaFitted_transformed], metric='roc_auc')\n",
        "cvDictbestpara_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Hw1yONRGiSNF"
      },
      "outputs": [],
      "source": [
        "transformer = FunctionTransformer(np.log1p)\n",
        "X_test_transform = transformer.transform(np.array(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkaRAaaxj7i0",
        "outputId": "71742688-ca8a-4d52-c8ec-76ee5056bcf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8610617616093497"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_y_ada_transform = bestAdaFitted_transformed.predict_proba(np.array(X_test_transform))[:,1]\n",
        "roc_auc_score(y_test, pred_y_ada_transform , average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwkeyL54kKAn",
        "outputId": "dce2faa9-ca6d-4c98-8c2b-74698e087856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8662139534262193"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_y_gb_transform = bestGbFitted_transformed.predict_proba(np.array(X_test_transform))[:,1]\n",
        "roc_auc_score(y_test, pred_y_gb_transform , average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L33hedWkkRKf"
      },
      "source": [
        "### Voting based ensamble model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkmz5JGj_BYG"
      },
      "source": [
        "The voting based ensamble model combines the predictions of multiple individual models to make a final prediction. Each individual model is trained independently. When making predictions, each model generates its prediction, and then a voting mechanism is used to determine the final prediction.\n",
        "\n",
        "There are different types of voting mechanisms used in ensemble models, and here we choose the **soft voting**. It calculates the probabilities  predicted by each individual model for each class. The final prediction is determined by averaging the predicted probabilities across all models and selecting the class with the highest combined probability.\n",
        "\n",
        "Here we use the weighted average and give Grident Boosting more weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_L-PWiskQx-",
        "outputId": "d6d9c216-c81e-4495-a156-c7a03b9b8a15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting_transform = VotingClassifier(estimators=[('gb', bestGbFitted_transformed),\n",
        "                                         ('ada', bestAdaFitted_transformed)], voting='soft',weights=[2,1])\n",
        "voting_transform = voting_transform.fit(X_train_transform, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtvZ453kkYwa",
        "outputId": "76cd5345-3537-4c6e-ce7b-269cb27cb35d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9355733333333334"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_vote_transform = voting_transform.predict_proba(np.array(X_test_transform))[:,1]\n",
        "voting_transform.score(X_test_transform, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgAPOY7qAE4y"
      },
      "source": [
        "The ROC_AUC score of the voting ensamble model is not better than the single model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Uj6tgjJkftn",
        "outputId": "6e53becf-d4be-4fcb-8627-a82c3aa10c00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8662745151327746"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "roc_auc_score(y_test, y_pred_vote_transform , average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqrG3pS-ARe6"
      },
      "source": [
        "We also try to ensamble models trained with untransformed features. However, the ROC_AUC score also doesn't improve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIOV_zYImDd1",
        "outputId": "d248ff1a-e11b-4832-dede-2f387ef1a976"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8663124310949759"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voting = VotingClassifier(estimators=[('gb', bestGb), ('ada', bestAda)],\n",
        "                                 voting='soft',weights=[2,1])\n",
        "voting = voting.fit(X_train, y_train)\n",
        "\n",
        "y_pred_vote =voting.predict_proba(np.array(X_test.values))[:,1]\n",
        "roc_auc_score(y_test, y_pred_vote, average='macro', sample_weight=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIRvtETAks-0"
      },
      "source": [
        "### Testing on Real Test Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGLi0q2BAlqv"
      },
      "source": [
        "Finally, we need to predict on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FJqDsuJUktRb"
      },
      "outputs": [],
      "source": [
        "# Read Training dataset as well as drop the index column\n",
        "test_data = pd.read_csv('/content/cs-test.csv').drop('Unnamed: 0', axis = 1)\n",
        "# For each column heading we replace \"-\" and convert the heading in lowercase\n",
        "cleancolumn = []\n",
        "for i in range(len(test_data.columns)):\n",
        "    cleancolumn.append(test_data.columns[i].replace('-', '').lower())\n",
        "test_data.columns = cleancolumn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23BUjPlQAtB7"
      },
      "source": [
        "#### Data Preprocessing on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "d5-ZR1lYlSRM"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.iloc[:, 1:]\n",
        "test_data.fillna((test_data.median()), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GaOGxooA3dp"
      },
      "source": [
        "#### Prediction with Voting ensambled model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybVbCkdolgjA",
        "outputId": "94e5f7be-90c5-4d51-d29a-cddeb13dd547"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101503\n"
          ]
        }
      ],
      "source": [
        "pred_y_voting = voting.predict_proba(np.array(test_data.values))[:,1]\n",
        "print (len(pred_y_voting))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gTgtv1NjneDc"
      },
      "outputs": [],
      "source": [
        "output = pd.DataFrame({'ID':test_data.index, 'probability':pred_y_voting})\n",
        "output.to_csv(\"./predictions.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GbgWYdBnnrb",
        "outputId": "bca432c9-ea72-48f7-9c6c-cca66bfb7648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101503\n"
          ]
        }
      ],
      "source": [
        "test_data_transform = transformer.transform(np.array(test_data))\n",
        "\n",
        "pred_y_voting_transform = voting_transform.predict_proba(np.array(test_data.values))[:,1]\n",
        "print(len(pred_y_voting_transform))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "qtdcetj6oBz0"
      },
      "outputs": [],
      "source": [
        "output_transform = pd.DataFrame({'ID':test_data.index, 'probability':pred_y_voting_transform})\n",
        "output.to_csv(\"./predictions_voting_Feature_transformation.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTClG35poJaZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
